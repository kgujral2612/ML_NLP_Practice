{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39d7a482",
   "metadata": {},
   "source": [
    "# Sentiment Analysis using Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "6f9d3da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/kaushambigujral/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/kaushambigujral/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/kaushambigujral/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "9d81afe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserName</th>\n",
       "      <th>ScreenName</th>\n",
       "      <th>Location</th>\n",
       "      <th>TweetAt</th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3799</td>\n",
       "      <td>48751</td>\n",
       "      <td>London</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3800</td>\n",
       "      <td>48752</td>\n",
       "      <td>UK</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>advice Talk to your neighbours family to excha...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3801</td>\n",
       "      <td>48753</td>\n",
       "      <td>Vagabonds</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3802</td>\n",
       "      <td>48754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>My food stock is not the only one which is emp...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3803</td>\n",
       "      <td>48755</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Me, ready to go at supermarket during the #COV...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserName  ScreenName   Location     TweetAt  \\\n",
       "0      3799       48751     London  16-03-2020   \n",
       "1      3800       48752         UK  16-03-2020   \n",
       "2      3801       48753  Vagabonds  16-03-2020   \n",
       "3      3802       48754        NaN  16-03-2020   \n",
       "4      3803       48755        NaN  16-03-2020   \n",
       "\n",
       "                                       OriginalTweet           Sentiment  \n",
       "0  @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...             Neutral  \n",
       "1  advice Talk to your neighbours family to excha...            Positive  \n",
       "2  Coronavirus Australia: Woolworths to give elde...            Positive  \n",
       "3  My food stock is not the only one which is emp...            Positive  \n",
       "4  Me, ready to go at supermarket during the #COV...  Extremely Negative  "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv ('Corona_NLP_train.csv', encoding= 'latin-1')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c378e7cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82314"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = train_df[['OriginalTweet', 'Sentiment']]\n",
    "train_df.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "2da8befc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7596"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('Corona_NLP_test.csv', encoding = 'latin-1')\n",
    "test_df = test_df[['OriginalTweet', 'Sentiment']]\n",
    "test_df.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "90d7610f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRENDING: New Yorkers encounter empty supermar...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When I couldn't find hand sanitizer at Fred Me...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Find out how you can protect yourself and love...</td>\n",
       "      <td>Extremely Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#Panic buying hits #NewYork City as anxious sh...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#toiletpaper #dunnypaper #coronavirus #coronav...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3793</th>\n",
       "      <td>Meanwhile In A Supermarket in Israel -- People...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3794</th>\n",
       "      <td>Did you panic buy a lot of non-perishable item...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3795</th>\n",
       "      <td>Asst Prof of Economics @cconces was on @NBCPhi...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3796</th>\n",
       "      <td>Gov need to do somethings instead of biar je r...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3797</th>\n",
       "      <td>I and @ForestandPaper members are committed to...</td>\n",
       "      <td>Extremely Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3798 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          OriginalTweet           Sentiment\n",
       "0     TRENDING: New Yorkers encounter empty supermar...  Extremely Negative\n",
       "1     When I couldn't find hand sanitizer at Fred Me...            Positive\n",
       "2     Find out how you can protect yourself and love...  Extremely Positive\n",
       "3     #Panic buying hits #NewYork City as anxious sh...            Negative\n",
       "4     #toiletpaper #dunnypaper #coronavirus #coronav...             Neutral\n",
       "...                                                 ...                 ...\n",
       "3793  Meanwhile In A Supermarket in Israel -- People...            Positive\n",
       "3794  Did you panic buy a lot of non-perishable item...            Negative\n",
       "3795  Asst Prof of Economics @cconces was on @NBCPhi...             Neutral\n",
       "3796  Gov need to do somethings instead of biar je r...  Extremely Negative\n",
       "3797  I and @ForestandPaper members are committed to...  Extremely Positive\n",
       "\n",
       "[3798 rows x 2 columns]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "384e3f28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    TRENDING: New Yorkers encounter empty supermar...\n",
       "1    When I couldn't find hand sanitizer at Fred Me...\n",
       "2    Find out how you can protect yourself and love...\n",
       "Name: OriginalTweet, dtype: object"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['OriginalTweet'][:3]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8d75e6",
   "metadata": {},
   "source": [
    "## Exploratory Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97534f4f",
   "metadata": {},
   "source": [
    "Check for null values in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "9c10e34c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    41157\n",
      "Name: OriginalTweet, dtype: int64\n",
      "False    41157\n",
      "Name: Sentiment, dtype: int64\n",
      "\n",
      "False    3798\n",
      "Name: OriginalTweet, dtype: int64\n",
      "False    3798\n",
      "Name: Sentiment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for column in train_df.columns:\n",
    "    print(train_df[column].isnull().value_counts())\n",
    "print()  \n",
    "for column in test_df.columns:\n",
    "    print(test_df[column].isnull().value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d191b24",
   "metadata": {},
   "source": [
    "Check for duplicate values in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "1d895ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    41157\n",
      "dtype: int64\n",
      "\n",
      "False    3798\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_df.duplicated().value_counts())\n",
    "print()\n",
    "print(test_df.duplicated().value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab4b60f",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "- Removing links(https) and mentions(@)\n",
    "- Creating tokens\n",
    "- Stopword removal\n",
    "- Lemmatizing tokens\n",
    "- Un-tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "32472c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text_df):\n",
    "    # converting to lowercase\n",
    "    text_df = text_df.apply(lambda x: x.lower())\n",
    "    print('Converted to lower case')\n",
    "    #Removing links and mentions\n",
    "    text_df = text_df.apply(lambda x: re.sub(r\"((www.[^s]+)|(http\\S+)|(@\\S+))\", '', x))\n",
    "    print('Removed links and mentions')\n",
    "    #Tokenization\n",
    "    text_df = text_df.apply(lambda x: nltk.tokenize.RegexpTokenizer(r\"\\w+\").tokenize(x))\n",
    "    print('Tokenized')\n",
    "    #Stopword removal\n",
    "    text_df = text_df.apply(lambda x: [i for i in x if i not in nltk.corpus.stopwords.words('english')])\n",
    "    print('Removed stop words')\n",
    "    #lemmatization\n",
    "    lm = nltk.WordNetLemmatizer()\n",
    "    print('Lemmatized')\n",
    "    text_df = text_df.apply(lambda x: [lm.lemmatize(i) for i in x])\n",
    "    # Un- Tokenizing\n",
    "    text_df = text_df.apply(lambda x: ' '.join(x))\n",
    "    print('Untokenized')\n",
    "    return text_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "f7512ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted to lower case\n",
      "Removed links and mentions\n",
      "Tokenized\n",
      "Removed stop words\n",
      "Lemmatized\n",
      "Untokenized\n"
     ]
    }
   ],
   "source": [
    "train_tweets = preprocess(train_df['OriginalTweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "068c2afd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                         \n",
       "1        advice talk neighbour family exchange phone nu...\n",
       "2        coronavirus australia woolworth give elderly d...\n",
       "3        food stock one empty please panic enough food ...\n",
       "4        ready go supermarket covid19 outbreak paranoid...\n",
       "                               ...                        \n",
       "41152    airline pilot offering stock supermarket shelf...\n",
       "41153    response complaint provided citing covid 19 re...\n",
       "41154    know itâ getting tough rationing toilet paper ...\n",
       "41155    wrong smell hand sanitizer starting turn coron...\n",
       "41156    well new used rift going 700 00 amazon rn alth...\n",
       "Name: OriginalTweet, Length: 41157, dtype: object"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "ea2d6baa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>PreprocessedTweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>advice Talk to your neighbours family to excha...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>advice talk neighbour family exchange phone nu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>coronavirus australia woolworth give elderly d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My food stock is not the only one which is emp...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>food stock one empty please panic enough food ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Me, ready to go at supermarket during the #COV...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "      <td>ready go supermarket covid19 outbreak paranoid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       OriginalTweet           Sentiment  \\\n",
       "0  @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...             Neutral   \n",
       "1  advice Talk to your neighbours family to excha...            Positive   \n",
       "2  Coronavirus Australia: Woolworths to give elde...            Positive   \n",
       "3  My food stock is not the only one which is emp...            Positive   \n",
       "4  Me, ready to go at supermarket during the #COV...  Extremely Negative   \n",
       "\n",
       "                                   PreprocessedTweet  \n",
       "0                                                     \n",
       "1  advice talk neighbour family exchange phone nu...  \n",
       "2  coronavirus australia woolworth give elderly d...  \n",
       "3  food stock one empty please panic enough food ...  \n",
       "4  ready go supermarket covid19 outbreak paranoid...  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['PreprocessedTweet'] = train_tweets\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8614a896",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "f44aacc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41157, 43471)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "tweet_vector = vectorizer.fit_transform(train_df['PreprocessedTweet'])\n",
    "tweet_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "a3c00000",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data into 80% training and 20% testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(tweet_vector, train_df.Sentiment, test_size=0.20,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "aaaff28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and train the Naive Bayes Classifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifier = MultinomialNB().fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "ec2b614e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Extremely Positive' 'Extremely Negative' 'Extremely Negative' ...\n",
      " 'Positive' 'Neutral' 'Positive']\n",
      "['Neutral' 'Negative' 'Positive' ... 'Neutral' 'Neutral' 'Positive']\n"
     ]
    }
   ],
   "source": [
    "print(classifier.predict(xtest))\n",
    "print(ytest.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "ee33e3f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "Extremely Negative       0.89      0.63      0.74      4387\n",
      "Extremely Positive       0.85      0.68      0.76      5293\n",
      "          Negative       0.68      0.78      0.73      7931\n",
      "           Neutral       0.91      0.57      0.70      6187\n",
      "          Positive       0.63      0.87      0.73      9127\n",
      "\n",
      "          accuracy                           0.73     32925\n",
      "         macro avg       0.79      0.71      0.73     32925\n",
      "      weighted avg       0.76      0.73      0.73     32925\n",
      "\n",
      "\n",
      "Confusion Matrix: \n",
      " [[2765   29 1143   51  399]\n",
      " [  22 3625  229   27 1390]\n",
      " [ 213  137 6200  150 1231]\n",
      " [  50  109  888 3510 1630]\n",
      " [  73  340  670  130 7914]]\n",
      "Accuracy: \n",
      " 0.7293545937737281\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model on the training data set\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "pred = classifier.predict(xtrain)\n",
    "print(classification_report(ytrain, pred))\n",
    "print()\n",
    "print(\"Confusion Matrix: \\n\", confusion_matrix(ytrain, pred))\n",
    "print(\"Accuracy: \\n\", accuracy_score(ytrain, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "23636e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "Extremely Negative       0.60      0.35      0.44      1094\n",
      "Extremely Positive       0.56      0.39      0.46      1331\n",
      "          Negative       0.43      0.53      0.47      1986\n",
      "           Neutral       0.67      0.37      0.48      1526\n",
      "          Positive       0.41      0.61      0.49      2295\n",
      "\n",
      "          accuracy                           0.48      8232\n",
      "         macro avg       0.54      0.45      0.47      8232\n",
      "      weighted avg       0.51      0.48      0.47      8232\n",
      "\n",
      "\n",
      "Confusion Matrix: \n",
      " [[ 385    6  540   24  139]\n",
      " [   6  522   83   23  697]\n",
      " [ 167   63 1046   93  617]\n",
      " [  33   45  326  570  552]\n",
      " [  50  290  428  137 1390]]\n",
      "Accuracy: \n",
      " 0.47534013605442177\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model on the testing data set\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "pred = classifier.predict(xtest)\n",
    "print(classification_report(ytest, pred))\n",
    "print()\n",
    "print(\"Confusion Matrix: \\n\", confusion_matrix(ytest, pred))\n",
    "print(\"Accuracy: \\n\", accuracy_score(ytest, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1969a1",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "778cf924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3798, 43471)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test_df['PreprocessedTweet'] = preprocess(test_df['OriginalTweet'])\n",
    "test_tweet_vector = vectorizer.transform(test_df['OriginalTweet'])\n",
    "test_tweet_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "ac6238d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Extremely Negative' 'Positive' 'Extremely Positive' ... 'Neutral'\n",
      " 'Extremely Negative' 'Extremely Positive']\n",
      "0       Extremely Negative\n",
      "1                 Positive\n",
      "2       Extremely Positive\n",
      "3                 Negative\n",
      "4                  Neutral\n",
      "               ...        \n",
      "3793              Positive\n",
      "3794              Negative\n",
      "3795               Neutral\n",
      "3796    Extremely Negative\n",
      "3797    Extremely Positive\n",
      "Name: Sentiment, Length: 3798, dtype: object\n"
     ]
    }
   ],
   "source": [
    "pred = classifier.predict(test_tweet_vector)\n",
    "print(pred)\n",
    "print(test_df.Sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "b96dadae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "Extremely Negative       0.53      0.35      0.42       592\n",
      "Extremely Positive       0.56      0.42      0.48       599\n",
      "          Negative       0.39      0.55      0.45      1041\n",
      "           Neutral       0.58      0.23      0.33       619\n",
      "          Positive       0.38      0.49      0.43       947\n",
      "\n",
      "          accuracy                           0.43      3798\n",
      "         macro avg       0.49      0.41      0.42      3798\n",
      "      weighted avg       0.47      0.43      0.43      3798\n",
      "\n",
      "\n",
      "Confusion Matrix: \n",
      " [[210  10 306  13  53]\n",
      " [ 16 249  83   8 243]\n",
      " [128  42 570  53 248]\n",
      " [ 15  20 212 142 230]\n",
      " [ 30 120 302  29 466]]\n",
      "Accuracy: \n",
      " 0.4310163243812533\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_df.Sentiment, pred))\n",
    "print()\n",
    "print(\"Confusion Matrix: \\n\", confusion_matrix(test_df.Sentiment, pred))\n",
    "print(\"Accuracy: \\n\", accuracy_score(test_df.Sentiment, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafc6f52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
